1、线性回归
  线性回归通过使用最佳的拟合直线（又被称为回归线），建立因变量（Y）和一个或多个自变量（X）之间的关系。
  注意：
  ·自变量和因变量之间必须满足线性关系
  ·多元回归存在多重共线性，自相关性和异方差性。
  ·线性回归对异常值非常敏感。异常值会严重影响回归线和最终的预测值
  ·多重共线性会增加系数估计的方差，并且使得估计对模型中的微小变化非常敏感。结果是系数估计不稳定
  ·在多个自变量的情况下，我们可以采用正向选择、向后消除和逐步选择的方法来选择最重要的自变量
2、逻辑回归
  逻辑回归广泛用于分类问题
  注意：
   ·逻辑回归不要求因变量和自变量之间是线性关系，它可以处理多类型关系，因为它对预测输出进行了非线性 log 变换
   ·为了避免过拟合和欠拟合，我们应该涵盖所有有用的变量。实际中确保这种情况的一个好的做法是使用逐步筛选的方法来估计逻辑回归
   ·训练样本数量越大越好，因为如果样本数量少，最大似然估计的效果就会比最小二乘法差。
   ·自变量不应相互关联，即不存在多重共线性。然而，在分析和建模中，我们可以选择包含分类变量相互作用的影响
   ·如果因变量的值是序数，则称之为序数逻辑回归
   ·如果因变量是多类别的，则称之为多元逻辑回归
